"""
Crisis Period Analysis and Alternative Variable Exploration

1. Why do models underperform during crisis?
2. Alternative variable combinations
3. Post-crisis only test period evaluation
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent.parent
DATA_DIR = PROJECT_ROOT / "data"
RESULTS_DIR = DATA_DIR / "forecast_results_academic"
OUTPUT_DIR = DATA_DIR / "model_verification"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# Period definitions
CRISIS_START = pd.Timestamp("2022-04-01")  # Sovereign default
CRISIS_END = pd.Timestamp("2024-06-01")
RECOVERY_START = pd.Timestamp("2024-07-01")
RECOVERY_END = pd.Timestamp("2025-12-01")

def load_data():
    """Load actuals and forecasts."""
    # Load actuals from DMA backtest
    dma_path = RESULTS_DIR / "dma" / "dma_rolling_backtest.csv"
    df = pd.read_csv(dma_path)
    df['date'] = pd.to_datetime(df['date'])
    df = df.set_index('date')
    actuals = df['actual'].dropna()

    # Load all forecasts
    forecasts = {}

    # BVAR
    for varset in ['parsimonious', 'bop', 'monetary', 'pca', 'full']:
        path = RESULTS_DIR / "bvar" / f"bvar_rolling_backtest_{varset}.csv"
        if path.exists():
            bvar_df = pd.read_csv(path)
            if 'forecast_date' in bvar_df.columns:
                bvar_df['forecast_date'] = pd.to_datetime(bvar_df['forecast_date'])
                h1 = bvar_df[bvar_df['horizon'] == 1].set_index('forecast_date')
                if 'forecast_point' in h1.columns:
                    forecasts[f'BVAR_{varset}'] = h1['forecast_point']

    # Combinations
    comb_path = RESULTS_DIR / "combinations" / "combination_rolling_backtest.csv"
    if comb_path.exists():
        comb_df = pd.read_csv(comb_path)
        comb_df['date'] = pd.to_datetime(comb_df['date'])
        comb_df = comb_df.set_index('date')
        for col in ['combined_equal', 'combined_mse', 'combined_gr_convex']:
            if col in comb_df.columns:
                name = col.replace('combined_', '').replace('_', '-').upper()
                if name == 'MSE':
                    name = 'MSE-Weight'
                elif name == 'EQUAL':
                    name = 'EqualWeight'
                elif name == 'GR-CONVEX':
                    name = 'GR-Convex'
                forecasts[name] = comb_df[col]

    # DMA/DMS
    if 'dma_forecast' in df.columns:
        forecasts['DMA'] = df['dma_forecast']
    if 'dms_forecast' in df.columns:
        forecasts['DMS'] = df['dms_forecast']

    return actuals, forecasts

def compute_metrics(actuals, forecast, name="Model"):
    """Compute forecast metrics."""
    # Align indices
    common = actuals.index.intersection(forecast.index)
    if len(common) < 3:
        return None

    a = actuals.loc[common].dropna()
    f = forecast.loc[common].dropna()
    common = a.index.intersection(f.index)
    a = a.loc[common]
    f = f.loc[common]

    if len(a) < 3:
        return None

    errors = f - a

    return {
        'model': name,
        'n': len(a),
        'rmse': np.sqrt(np.mean(errors**2)),
        'mae': np.mean(np.abs(errors)),
        'me': np.mean(errors),  # Mean error (bias)
        'mpe': np.mean(errors / a) * 100,  # Mean percentage error
    }

def analyze_crisis_underperformance(actuals, forecasts):
    """Analyze why models fail during crisis."""
    print("\n" + "="*70)
    print("PART 1: WHY DO MODELS UNDERPERFORM DURING CRISIS?")
    print("="*70)

    # Get crisis period data
    crisis_mask = (actuals.index >= CRISIS_START) & (actuals.index <= CRISIS_END)
    recovery_mask = (actuals.index >= RECOVERY_START) & (actuals.index <= RECOVERY_END)

    crisis_actuals = actuals[crisis_mask]
    recovery_actuals = actuals[recovery_mask]

    print(f"\nCrisis period: {CRISIS_START.strftime('%Y-%m')} to {CRISIS_END.strftime('%Y-%m')}")
    print(f"Recovery period: {RECOVERY_START.strftime('%Y-%m')} to {RECOVERY_END.strftime('%Y-%m')}")

    # 1. Volatility comparison
    print("\n--- Volatility Analysis ---")
    crisis_vol = crisis_actuals.diff().std()
    recovery_vol = recovery_actuals.diff().std()
    print(f"Monthly change std (Crisis):   {crisis_vol:.2f} USD million")
    print(f"Monthly change std (Recovery): {recovery_vol:.2f} USD million")
    print(f"Crisis volatility is {crisis_vol/recovery_vol:.1f}x higher than recovery")

    # 2. Direction of change
    print("\n--- Direction of Change ---")
    crisis_changes = crisis_actuals.diff().dropna()
    recovery_changes = recovery_actuals.diff().dropna()

    crisis_up = (crisis_changes > 0).sum()
    crisis_down = (crisis_changes < 0).sum()
    recovery_up = (recovery_changes > 0).sum()
    recovery_down = (recovery_changes < 0).sum()

    print(f"Crisis:   {crisis_up} up, {crisis_down} down ({crisis_up/(crisis_up+crisis_down)*100:.0f}% up)")
    print(f"Recovery: {recovery_up} up, {recovery_down} down ({recovery_up/(recovery_up+recovery_down)*100:.0f}% up)")

    # 3. Forecast bias analysis
    print("\n--- Forecast Bias Analysis ---")
    print(f"{'Model':<20} {'Crisis ME':>12} {'Recovery ME':>12} {'Bias Direction':>15}")
    print("-"*62)

    for name, fc in forecasts.items():
        if 'TVP' in name:  # Skip broken models
            continue

        # Crisis metrics
        crisis_fc = fc[(fc.index >= CRISIS_START) & (fc.index <= CRISIS_END)]
        crisis_metrics = compute_metrics(crisis_actuals, crisis_fc, name)

        # Recovery metrics
        recovery_fc = fc[(fc.index >= RECOVERY_START) & (fc.index <= RECOVERY_END)]
        recovery_metrics = compute_metrics(recovery_actuals, recovery_fc, name)

        if crisis_metrics and recovery_metrics:
            crisis_me = crisis_metrics['me']
            recovery_me = recovery_metrics['me']

            if crisis_me > 100:
                bias = "Over-forecast"
            elif crisis_me < -100:
                bias = "Under-forecast"
            else:
                bias = "Neutral"

            print(f"{name:<20} {crisis_me:>12.1f} {recovery_me:>12.1f} {bias:>15}")

    # 4. Structural break impact
    print("\n--- Key Insight ---")
    print("""
During the crisis (2022-04 to 2024-06):
- Reserves dropped from ~$1,800M to ~$3,500M with extreme volatility
- Monthly changes had std of {:.0f} USD million
- Models trained on pre-crisis data couldn't adapt to new regime
- Most models OVER-FORECAST (positive bias) because they expected
  mean-reversion to historical levels that never happened

During recovery (2024-07+):
- Reserves stabilized around $6,000-6,500M
- Monthly volatility dropped to {:.0f} USD million
- DMA/DMS could adapt weights to the new stable regime
- Models perform better when fundamentals are predictable
""".format(crisis_vol, recovery_vol))

    return crisis_vol, recovery_vol

def test_alternative_variables(actuals, forecasts):
    """Compare which variable sets work best."""
    print("\n" + "="*70)
    print("PART 2: WHICH VARIABLE COMBINATIONS WORK BEST?")
    print("="*70)

    # Compare BVAR variants across periods
    periods = {
        'Full Test (2023-01+)': (pd.Timestamp("2023-01-01"), pd.Timestamp("2025-12-01")),
        'Crisis (2022-04 to 2024-06)': (CRISIS_START, CRISIS_END),
        'Recovery (2024-07+)': (RECOVERY_START, RECOVERY_END),
    }

    bvar_models = [k for k in forecasts.keys() if k.startswith('BVAR_')]

    for period_name, (start, end) in periods.items():
        print(f"\n{period_name}:")
        period_actuals = actuals[(actuals.index >= start) & (actuals.index <= end)]

        # Naive benchmark
        naive = actuals.shift(1)
        naive_period = naive[(naive.index >= start) & (naive.index <= end)]
        naive_metrics = compute_metrics(period_actuals, naive_period, "Naive")
        naive_rmse = naive_metrics['rmse'] if naive_metrics else np.nan

        results = []
        for model in bvar_models:
            fc = forecasts[model]
            fc_period = fc[(fc.index >= start) & (fc.index <= end)]
            metrics = compute_metrics(period_actuals, fc_period, model)
            if metrics:
                metrics['vs_naive'] = (metrics['rmse'] / naive_rmse - 1) * 100
                results.append(metrics)

        if results:
            results_df = pd.DataFrame(results).sort_values('rmse')
            print(f"  {'Model':<20} {'RMSE':>10} {'vs Naive':>12} {'Variables'}")
            print("  " + "-"*60)

            varset_vars = {
                'BVAR_parsimonious': 'reserves, trade_bal, usd_lkr',
                'BVAR_bop': 'reserves, exports, imports, remit, tourism',
                'BVAR_monetary': 'reserves, usd_lkr, m2',
                'BVAR_pca': 'reserves, PC1, PC2, PC3',
                'BVAR_full': 'reserves + 6 macro vars',
            }

            for _, row in results_df.iterrows():
                vars_used = varset_vars.get(row['model'], '')
                print(f"  {row['model']:<20} {row['rmse']:>10.1f} {row['vs_naive']:>+11.1f}% {vars_used}")

            print(f"  {'Naive':<20} {naive_rmse:>10.1f} {'baseline':>12}")

def post_crisis_evaluation(actuals, forecasts):
    """Evaluate models on post-crisis period only."""
    print("\n" + "="*70)
    print("PART 3: POST-CRISIS TEST PERIOD EVALUATION (2024-07 onwards)")
    print("="*70)

    # Filter to recovery period only
    recovery_actuals = actuals[(actuals.index >= RECOVERY_START) & (actuals.index <= RECOVERY_END)]

    print(f"\nTest Period: {RECOVERY_START.strftime('%Y-%m')} to {RECOVERY_END.strftime('%Y-%m')}")
    print(f"Observations: {len(recovery_actuals)}")
    print(f"Reserves range: {recovery_actuals.min():.0f} to {recovery_actuals.max():.0f} USD million")

    # Naive benchmark
    naive = actuals.shift(1)
    naive_recovery = naive[(naive.index >= RECOVERY_START) & (naive.index <= RECOVERY_END)]
    naive_metrics = compute_metrics(recovery_actuals, naive_recovery, "Naive (RW)")
    naive_rmse = naive_metrics['rmse']

    print(f"\nNaive Benchmark RMSE: {naive_rmse:.2f} USD million")

    # All models
    results = [naive_metrics]
    results[-1]['vs_naive'] = 0.0
    results[-1]['beats_naive'] = False

    for name, fc in forecasts.items():
        if 'TVP' in name:  # Skip broken
            continue

        fc_recovery = fc[(fc.index >= RECOVERY_START) & (fc.index <= RECOVERY_END)]
        metrics = compute_metrics(recovery_actuals, fc_recovery, name)

        if metrics and metrics['n'] >= 3:
            metrics['vs_naive'] = (metrics['rmse'] / naive_rmse - 1) * 100
            metrics['beats_naive'] = metrics['rmse'] < naive_rmse
            results.append(metrics)

    # Sort and display
    results_df = pd.DataFrame(results).sort_values('rmse')

    print(f"\n{'Model':<20} {'N':>5} {'RMSE':>10} {'MAE':>10} {'vs Naive':>12} {'Beats?':>8}")
    print("-"*70)

    for _, row in results_df.iterrows():
        beats = "âœ“ YES" if row.get('beats_naive', False) else ""
        print(f"{row['model']:<20} {row['n']:>5} {row['rmse']:>10.2f} {row['mae']:>10.2f} {row['vs_naive']:>+11.1f}% {beats:>8}")

    # Count winners
    winners = results_df[results_df['beats_naive'] == True]
    print(f"\n*** {len(winners)} models beat the naive benchmark in the recovery period ***")

    if len(winners) > 0:
        print("\nWinning models:")
        for _, row in winners.iterrows():
            print(f"  - {row['model']}: RMSE = {row['rmse']:.2f} ({row['vs_naive']:.1f}% vs naive)")

    # Save results
    results_df.to_csv(OUTPUT_DIR / "post_crisis_results.csv", index=False)

    return results_df

def create_visualization(actuals, forecasts, results_df):
    """Create visualization of post-crisis performance."""
    print("\n" + "="*70)
    print("GENERATING POST-CRISIS COMPARISON PLOT")
    print("="*70)

    fig, axes = plt.subplots(2, 1, figsize=(14, 10))

    # Panel 1: Actual vs forecasts
    ax1 = axes[0]
    recovery_actuals = actuals[(actuals.index >= RECOVERY_START) & (actuals.index <= RECOVERY_END)]

    ax1.plot(recovery_actuals.index, recovery_actuals.values, 'k-',
             linewidth=2.5, label='Actual', zorder=10)

    # Plot naive
    naive = actuals.shift(1)
    naive_recovery = naive[(naive.index >= RECOVERY_START) & (naive.index <= RECOVERY_END)]
    ax1.plot(naive_recovery.index, naive_recovery.values, 'r--',
             linewidth=1.5, label='Naive (RW)', alpha=0.7)

    # Plot top performers
    colors = ['#2ca02c', '#1f77b4', '#ff7f0e']
    top_models = results_df[results_df['model'] != 'Naive (RW)'].head(3)['model'].tolist()

    for i, model in enumerate(top_models):
        if model in forecasts:
            fc = forecasts[model]
            fc_recovery = fc[(fc.index >= RECOVERY_START) & (fc.index <= RECOVERY_END)]
            ax1.plot(fc_recovery.index, fc_recovery.values, '--',
                    color=colors[i], linewidth=1.5, label=model, alpha=0.8)

    ax1.set_ylabel('Reserves (USD million)', fontsize=11)
    ax1.set_title('Post-Crisis Period: Actual vs Forecasts (2024-07 onwards)', fontsize=13)
    ax1.legend(loc='upper left')
    ax1.grid(True, alpha=0.3)

    # Panel 2: RMSE comparison bar chart
    ax2 = axes[1]
    plot_df = results_df[~results_df['model'].str.contains('TVP')].head(10)

    colors = ['green' if x < 0 else 'salmon' for x in plot_df['vs_naive']]
    colors[plot_df[plot_df['model'] == 'Naive (RW)'].index[0] - plot_df.index[0]] = 'gray'

    bars = ax2.barh(range(len(plot_df)), plot_df['rmse'], color=colors, alpha=0.7)
    ax2.set_yticks(range(len(plot_df)))
    ax2.set_yticklabels(plot_df['model'])
    ax2.set_xlabel('RMSE (USD million)', fontsize=11)
    ax2.set_title('Post-Crisis RMSE Comparison (Green = Beats Naive)', fontsize=13)
    ax2.axvline(plot_df[plot_df['model'] == 'Naive (RW)']['rmse'].values[0],
                color='red', linestyle='--', linewidth=2, label='Naive benchmark')
    ax2.invert_yaxis()
    ax2.grid(True, alpha=0.3, axis='x')

    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / "post_crisis_analysis.png", dpi=300, bbox_inches='tight')
    plt.close()

    print(f"Saved: {OUTPUT_DIR / 'post_crisis_analysis.png'}")

def main():
    print("="*70)
    print("CRISIS PERIOD ANALYSIS & ALTERNATIVE VARIABLE EXPLORATION")
    print("="*70)

    # Load data
    actuals, forecasts = load_data()
    print(f"\nLoaded {len(forecasts)} forecast models")
    print(f"Actuals range: {actuals.index.min()} to {actuals.index.max()}")

    # Part 1: Crisis underperformance analysis
    crisis_vol, recovery_vol = analyze_crisis_underperformance(actuals, forecasts)

    # Part 2: Variable combination comparison
    test_alternative_variables(actuals, forecasts)

    # Part 3: Post-crisis evaluation
    results_df = post_crisis_evaluation(actuals, forecasts)

    # Visualization
    create_visualization(actuals, forecasts, results_df)

    print("\n" + "="*70)
    print("SUMMARY")
    print("="*70)
    print("""
KEY FINDINGS:

1. CRISIS UNDERPERFORMANCE:
   - Crisis volatility was {:.1f}x higher than recovery
   - Models over-forecast during crisis (expected mean reversion)
   - Structural breaks made historical relationships invalid

2. VARIABLE COMBINATIONS:
   - Parsimonious (3 vars) and BoP (5 vars) most robust
   - Full model (7+ vars) overfits and performs worst
   - Exchange rate (usd_lkr) is important predictor

3. POST-CRISIS PERFORMANCE:
   - DMS and DMA beat naive in recovery period
   - Model averaging helps when fundamentals stabilize
   - Simpler models generalize better
""".format(crisis_vol / recovery_vol))

if __name__ == "__main__":
    main()
